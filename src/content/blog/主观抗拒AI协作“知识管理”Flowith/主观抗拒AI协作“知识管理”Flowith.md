---
title: 主观抗拒AI协作“知识管理”Flowith
description: AI能离我的创作远点吗？
pubDate: 2025-03-02
modifiedDate: 2025-03-02
heroImage: ./Pasted image 20250403142543.png
heroAlt: ""
---

这篇文章由中英双语写作，仅代表个人观点
![[Pasted image 20250403142543.png]]

---

## **Not Safe**

Oh, my **besties!** ✨ **Who’s out there seriously building their personal knowledge base on Flowith?**

Don’t think that **worrying about data theft makes you paranoid**—protecting your information is just **common sense!** 

Like, **why** would you just hand over everything you’ve written to some random cloud storage?  That’s not just a bunch of scattered thoughts—**that’s your second brain!**

When I use Flomo, I don’t really care who sees my notes because, **first**, they’re just tiny fragments.  And **second**…  they’re **just tiny fragments!**

I don’t expect a bunch of random bits to magically turn into a full knowledge graph.  _Think about AI_—it sees fragmented and redundant information as **noise**. And honestly? What’s so valuable about **noise**?

But besties,  Flowith promotes itself as a tool to build your **personal knowledge base**. **Excuse me?**  Do you even know what having a second brain **means**? 

It’s your **connection** to the world, a **visualized record** of your thoughts colliding with reality.

Whether it’s the information I collect or my **original writing**, I **always** back things up **locally** before and after processing them. _That’s_ the foundation of creating a structured knowledge system. 
This is also why I prefer **Obsidian over Notion**. 

Let me say this **loud and clear**:  **Set boundaries for your deep content.**

 Creativity **without boundaries** is just **chaos**.

---

## **Not Accurate**



Second,  AI-generated content is **not accurate**. 

Professor Wang Shuyi has pointed this out—accuracy is **relative**, and sure, it’ll improve over time.  But some models handle AI hallucinations **better** than others… while some just throw out completely unnecessary or even **factually incorrect nonsense**. 
Do you really want to spend time **cleaning up that mess**?  Double-checking **every** fact?

If you blindly trust AI-generated content, then maybe…your knowledge base **doesn’t even mean that much to you**. 
I mean,  if you don’t care enough to **verify** what’s in it,  how valuable can it **really** be?

And if you **don’t** trust AI and feel the need to constantly double-check,  doesn’t that make your whole knowledge system **a chaotic, unreliable mess**? 
When you’re trying to figure out **why** a note doesn’t say what you wanted it to say,  can you **even trace** the source of the AI’s hallucination? 
At this point, **less is more**. Simplifying is **not** an easy process,  but it’s **necessary**. 

---

## **Not Comfortable**



Lastly,  how much of your workflow should actually involve AI?
I don’t know **how many people** have truly thought about this. 
If you’re just using AI for **fact-checking**, then great—it’s a useful learning tool. 
But if you’re serious about diving deep into a concept, then sure, Growith can do something to ignore you.
if you care about **security**, using a **locally deployed Obsidian setup with an MCP protocol for LLM client integration** is a much **more controlled approach**. 
In my setup,  every time the model wants access to an MD file, I **review the request carefully**.  _That level of control?_  **Super satisfying.** 

Maybe you haven’t thought about this,  but a well-managed knowledge system should feel **comfortable**—it should **enhance** your workflow,  not **disrupt** it.
When you’re **creating**, you want AI to do your **laundry and dishes**,  not mess with your **ideas**.
When you’re **organizing information**, you want to engage **all your senses**—your **eyes, ears, and even your voice**—not just your brain.
Your brain **isn’t** the only organ with processing power! 
Every time you **re-evaluate** and **filter information**,  you’re literally **rewiring your neurons**.

So besties, **don’t be lazy**.


**Ever.** 

---

## 不安全

拜托到底是谁在用Flowith认真地构建自己的知识库。你们不要以为被窃取数据是妄想症，请珍惜保护自己的数据安全。到底为什么可以把自己写的东西放心的交给任何云端啊？那不是一个碎片化的灵感，那可是你的“第二大脑”呀。我在使用flomo的时候不介意自己写出来的东西分享给谁，第一，它是碎片化的。第二，它是碎片化的，我不会期待一个零散的东西直接变成知识图谱。就像对于AI来说。零碎的冗余信息更像是噪音一样，一个噪音有什么可值得珍惜的？
但是朋友们， Flowers宣传的使用场景是构建自己的个人知识库。我的天。你们知道第二个大脑的意义是什么吗？是你跟这个世界的关联，是你的思想与这整个外界的碰撞的可视化记录。
不管是我所想要收集的信息还是自己原创的写作结果，把东西处理前后都放在本地备份是形成图谱知识的基础，这也是我不太使用notion而是选择Obsidian的原因。
再说一遍，为自己的深度内容树立好边界。没有边界的创作就没有真心。

## 不准确

第二点，AI生成的东西不准确。王树义老师提过这个问题，准确度上当然是相对的并且未来会获得改善的。关于AI幻觉有的模型会好很多，有的模型却多了很多人们根本就不需要甚至说跟事实不符合的信息。你还要花时间去处理这些数据吗？你要去验证自己得到的。生成结果是否是自己想要的吗？如果你真的这么信任这些生成内容，那说明这个知识库对于你的意义也不大。因为就连里面到底是否是你想要的你都不去验证。更别提多卡片的内容是否真正能建立关键词关联了。
如果你不信任这些生成的内容。愿意去反复审视自己得到的信息结果。你不觉得在这个时候，整个知识库的框架都已经变得不可控了吗？当你想要知道。手里的一句话，为什么不是你想要的时候你真的能找出那个幻觉的源头吗？
这个时候，极简才比较舒服，做减法不是一个容易的流程。

## 不舒服

最后，到底AI应该参与我们工作流多少流程的这件事情，我不知道有多少人思考过。如果只是信息验证的交叉验证，那当然是一个很有帮助的学习过程。请从这一点来说。如果你真的会死磕一个概念，确实growith可以容纳这样的使用场景。但就如我刚刚所说，如果要更安全的话，使用本地部署的Obsidian库，搭配MCP协议构建LLM客户端的集成，貌似是更可控的做法。
在我这个方案里面，每一次大模型想要获得md文件的任何访问许可，我都要仔细审查一下，这给我带来极大的舒服。可能你还没有思考过为什么知识管理会让人舒适，带来绝佳体验。
当你是在创作，你当然希望AI去给你打扫卫生洗衣服而不是干扰你的创作。当你是在学习整理信息。你当然希望能有更多的器官参与自己的学习过程。比如眼睛，嘴巴，耳朵；请记住，除了大脑，其它器官也有自己的cpu份额，每一次重新整理和自行筛选信息来源的过程，都是在重塑你的神经元。
不要在任何时候都偷懒。
